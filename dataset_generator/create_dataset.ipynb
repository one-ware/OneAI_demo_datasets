{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563d6805",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/one-ware/OneAI_demo_datasets/blob/main/dataset_generator/create_dataset.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd99a00",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generator\n",
    "\n",
    "Generate synthetic training datasets by placing objects on backgrounds with automatic labeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24afa686",
   "metadata": {},
   "source": [
    "## Quick Start Guide\n",
    "\n",
    "### Step 1: Choose Your Environment\n",
    "\n",
    "**Option A - Local Use:**\n",
    "- Skip cells marked with üåê (Google Colab only)\n",
    "- Use the configuration cell marked with üíª (Local)\n",
    "\n",
    "**Option B - Google Colab:**\n",
    "- Run cells marked with üåê (Google Colab)\n",
    "- Use the configuration cell marked with üåê (Colab)\n",
    "\n",
    "### Step 2: Prepare Your Images\n",
    "\n",
    "**Object Images (Required):**\n",
    "- Format: PNG with **transparent background**\n",
    "- Organize into folders by category (e.g., `/birds/`, `/drones/`)\n",
    "- Examples: bird.png, drone_01.png, etc.\n",
    "\n",
    "**Background Images (Required):**\n",
    "- Format: PNG or JPG\n",
    "- Place all in one folder\n",
    "- For video backgrounds: Name sequentially (e.g., `frame_0001.jpg`, `frame_0002.jpg`)\n",
    "\n",
    "### Step 3: Configure & Generate\n",
    "\n",
    "1. Set paths in the configuration cell\n",
    "2. Adjust parameters with sliders\n",
    "3. Run preview to check results\n",
    "4. Generate full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae864822",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Import necessary libraries and get images for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a62085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f048f9",
   "metadata": {},
   "source": [
    "#### üåê Google Colab Only: Video Frame Extraction\n",
    "\n",
    "*(Skip this if working locally or if you already have frame images)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, frame_skip=5):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while cap.isOpened() and frame_count < 500:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % frame_skip == 0:\n",
    "            output_path = os.path.join(output_folder, f\"frame_{saved_count:04d}.jpg\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            saved_count += 1\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {saved_count} frames to {output_folder}\")\n",
    "\n",
    "video_path = \"/content/video.mp4\"\n",
    "output_folder = \"/content/output_images\"\n",
    "extract_frames(video_path, output_folder, frame_skip=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12831448",
   "metadata": {},
   "source": [
    "#### üåê Google Colab Only: File Upload\n",
    "\n",
    "Upload your object and background images to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåê Google Colab Only - Upload files\n",
    "# Skip this cell if working locally\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# After upload, organize files into folders:\n",
    "# !mkdir -p /content/objects/birds\n",
    "# !mkdir -p /content/objects/drones\n",
    "# !mkdir -p /content/backgrounds\n",
    "# Then move uploaded files to appropriate folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26264f6",
   "metadata": {},
   "source": [
    "#### üåê Google Colab Only: Download Dataset Generator\n",
    "\n",
    "Download the required Python module from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåê Google Colab Only\n",
    "# Local users: Make sure dataset_generator.py is in the same folder as this notebook\n",
    "\n",
    "import requests\n",
    "\n",
    "# Replace this with the actual raw URL of your Python file\n",
    "file_url = \"https://raw.githubusercontent.com/one-ware/OneAI_demo_datasets/refs/heads/main/dataset_generator/dataset_generator.py\"\n",
    "file_name = \"dataset_generator.py\" # Name you want to save the file as\n",
    "\n",
    "try:\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"Successfully downloaded '{file_name}' from {file_url}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading the file: {e}\")\n",
    "    print(\"Please ensure the URL is correct and accessible (e.g., raw.githubusercontent.com for GitHub files).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438794c6",
   "metadata": {},
   "source": [
    "## Import Required Functions\n",
    "\n",
    "Run this cell to load the dataset generator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0da5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generator import (\n",
    "    load_background_metadata, \n",
    "    preload_backgrounds, \n",
    "    get_image_dataset_from_folder, \n",
    "    create_dataset_from_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ab876",
   "metadata": {},
   "source": [
    "## 1. Configure Paths and Categories\n",
    "\n",
    "### Object Image Requirements:\n",
    "- Must be PNG format with **transparent background**\n",
    "- Organize into separate folders by category\n",
    "- Example structure:\n",
    "  ```\n",
    "  /objects/\n",
    "    /birds/\n",
    "      bird_01.png\n",
    "      bird_02.png\n",
    "    /drones/\n",
    "      drone_01.png\n",
    "      drone_02.png\n",
    "  ```\n",
    "  - start label ids with 1\n",
    "\n",
    "### Background Image Requirements:\n",
    "- PNG or JPG format\n",
    "- All in one folder\n",
    "- For video backgrounds: Use sequential naming (frame_0001.jpg, frame_0002.jpg, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7777ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your object categories and adjust paths accordingly\n",
    "categories = [\n",
    "    {\"name\": \"bird\", \"folder\": \"/content/bird\", \"class_id\": 1},\n",
    "    {\"name\": \"drone\", \"folder\": \"/content/drone\", \"class_id\": 2},\n",
    "]\n",
    "\n",
    "# Background folder\n",
    "background_folder = \"/content/bg\"\n",
    "\n",
    "# Output path\n",
    "output_path = \"./generated_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedceec",
   "metadata": {},
   "source": [
    "## 2. Set Parameters\n",
    "\n",
    "Adjust these parameters to control how objects are placed on the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656609",
   "metadata": {},
   "source": [
    "### Explanation of Parameters\n",
    "\n",
    "The following parameters control the behavior of the synthetic dataset generation process:\n",
    "\n",
    "**Object Parameters**\n",
    "- **`min_scale_cm`**: Minimum size of objects in centimeters.\n",
    "- **`max_scale_cm`**: Maximum size of objects in centimeters.\n",
    "- **`rotation_range`**: Range of rotation angles for objects, specified in degrees (e.g., `(-1.0, 1.0)` for slight rotation).\n",
    "- **`allow_overlap`**: Boolean flag indicating whether objects are allowed to overlap. Controlled by the `allow_overlap` widget.\n",
    "- **`max_overlap_pct`**: Maximum allowable overlap between objects, as a percentage of their area.\n",
    "- **`min_object_distance_cm`**: Minimum distance between objects in centimeters to prevent crowding.\n",
    "\n",
    "**Placement Parameters**\n",
    "- **`edge_avoidance`**: Margin to keep objects away from the edges of the background, where `0.0` means no margin and `0.5` means a large margin.\n",
    "- **`prefer_center`**: Bias for placing objects closer to the center of the background, where `0.0` is uniform placement and `1.0` strongly favors the center.\n",
    "- **`category_weights`**: List of weights for each object category, determining the likelihood of each category appearing in the dataset.\n",
    "\n",
    "**Blending and Visual Quality**\n",
    "- **`object_blending_strength`**: Strength of blending at the edges of objects, where `0.0` results in sharp edges and `1.0` results in heavy blurring.\n",
    "\n",
    "**Dataset Composition**\n",
    "- **`number_of_objects_per_image`**: Tuple specifying the range of the number of objects per image (e.g., `(1, 4)` means 1 to 4 objects per image).\n",
    "- **`num_composite_images`**: Total number of images to generate in the dataset.\n",
    "\n",
    "**Background Parameters**\n",
    "- **`default_bg_width_cm`**: Default width of the background in centimeters.\n",
    "- **`default_placement_area_pct`**: Tuple specifying the placement area as percentages of the background dimensions (e.g., `(0.05, 0.05, 0.95, 0.6)` for a central region).\n",
    "\n",
    "**Output Parameters**\n",
    "- **`output_width`**: Width of the generated images in pixels.\n",
    "- **`output_height`**: Height of the generated images in pixels.\n",
    "- **`output_channels`**: Number of color channels in the output images (e.g., `3` for RGB).\n",
    "\n",
    "**Labeling and Validation**\n",
    "- **`max_labels`**: Maximum number of label boxes per image.\n",
    "- **`is_video_background`**: Boolean flag indicating whether the background is a video with different reference and test frames. In that case, reference images can be one frame before/after and it is assumed that the image frames can be ordered by name. Deactivate this setting if you want the same reference and test background image.\n",
    "\n",
    "These parameters are adjustable through the widgets in the notebook, allowing for fine-tuning of the dataset generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99060de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object size range in centimeters\n",
    "object_size_slider = widgets.FloatRangeSlider(\n",
    "    value=[11.0, 15.0], min=1.0, max=50.0, step=0.5,\n",
    "    description='Object Size (cm):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Rotation range in degrees\n",
    "rotation_slider = widgets.FloatRangeSlider(\n",
    "    value=[-1.0, 1.0], min=-180.0, max=180.0, step=1.0,\n",
    "    description='Rotation (¬∞):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Minimum distance between objects in centimeters\n",
    "min_distance_slider = widgets.FloatSlider(\n",
    "    value=2.0, min=0.0, max=10.0, step=0.5,\n",
    "    description='Min Distance (cm):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Keep objects away from edges (0.0 = no margin, 0.5 = large margin)\n",
    "edge_margin_slider = widgets.FloatSlider(\n",
    "    value=0.1, min=0.0, max=0.5, step=0.05,\n",
    "    description='Edge Margin:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Prefer center placement (0.0 = uniform, 1.0 = strongly centered)\n",
    "center_bias_slider = widgets.FloatSlider(\n",
    "    value=0.3, min=0.0, max=1.0, step=0.1,\n",
    "    description='Center Bias:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Blending strength (0.0 = sharp edges, 1.0 = heavily blurred)\n",
    "blending_slider = widgets.FloatSlider(\n",
    "    value=0.3, min=0.0, max=1.0, step=0.1,\n",
    "    description='Blending:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Number of objects per image\n",
    "num_objects_slider = widgets.IntRangeSlider(\n",
    "    value=[1, 4], min=1, max=20, step=1,\n",
    "    description='Objects/Image:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Number of images to generate\n",
    "num_images_input = widgets.IntText(\n",
    "    value=10, description='Total Images:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Image dimensions\n",
    "width_input = widgets.IntText(\n",
    "    value=1080, description='Width (px):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "height_input = widgets.IntText(\n",
    "    value=720, description='Height (px):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Background settings\n",
    "default_bg_width_cm = widgets.FloatText(\n",
    "    value=150.0, description='BG Width (cm):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "default_placement_area_width = widgets.FloatRangeSlider(\n",
    "    value=[0.05, 0.95], min=0.0, max=1.0, step=0.01,\n",
    "    description='Placement Area Width (%):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "default_placement_area_height = widgets.FloatRangeSlider(\n",
    "    value=[0.05, 0.95], min=0.0, max=1.0, step=0.01,\n",
    "    description='Placement Area Height (%):', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Set background info\n",
    "is_video_background = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Video Background (different ref/test frames)',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Overlap settings\n",
    "allow_overlap = widgets.Checkbox(\n",
    "    value=False, description='Allow Overlap',\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "max_overlap_pct = widgets.FloatSlider(\n",
    "    value=0.1, min=0.0, max=1.0, step=0.01,\n",
    "    description='Max Overlap (%):',\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Maximum number of label boxes per image\n",
    "max_labels = widgets.IntText(\n",
    "    value=10, description='Max Labels:', style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Display all controls with full width\n",
    "display(widgets.VBox([\n",
    "    default_bg_width_cm,\n",
    "    default_placement_area_width,\n",
    "    default_placement_area_height,\n",
    "    allow_overlap,\n",
    "    is_video_background,\n",
    "    max_overlap_pct,\n",
    "    max_labels\n",
    "], layout=widgets.Layout(width='90%')))\n",
    "\n",
    "display(widgets.VBox([\n",
    "    object_size_slider,\n",
    "    rotation_slider,\n",
    "    min_distance_slider,\n",
    "    edge_margin_slider,\n",
    "    center_bias_slider,\n",
    "    blending_slider,\n",
    "    num_objects_slider,\n",
    "    num_images_input,\n",
    "    width_input,\n",
    "    height_input\n",
    "], layout=widgets.Layout(width='90%')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372648f7",
   "metadata": {},
   "source": [
    "## 3. Preview\n",
    "\n",
    "**Generate 3 sample images** to verify your settings before creating the full dataset.\n",
    "\n",
    "The preview shows:\n",
    "- Left: Background image (reference frame)\n",
    "- Right: Background + objects (test frame) with bounding boxes\n",
    "\n",
    "**Check:**\n",
    "- ‚úÖ Object sizes look realistic\n",
    "- ‚úÖ Objects are placed in good positions\n",
    "- ‚úÖ Bounding boxes are accurate\n",
    "- ‚úÖ Class labels are correct\n",
    "\n",
    "If something looks wrong, adjust parameters above and run this cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "background_metadata = load_background_metadata(\n",
    "    [background_folder],\n",
    "    default_bg_width_cm=default_bg_width_cm.value,\n",
    "    default_placement_area_pct=(default_placement_area_width.value[0], default_placement_area_height.value[0], default_placement_area_width.value[1], default_placement_area_height.value[1])\n",
    ")\n",
    "background_images, bg_widths, bg_placement_areas = preload_backgrounds(background_metadata)\n",
    "\n",
    "category_datasets = []\n",
    "category_class_ids = []\n",
    "for cat in categories:\n",
    "    ds = get_image_dataset_from_folder(cat[\"folder\"])\n",
    "    category_datasets.append(ds)\n",
    "    category_class_ids.append(cat[\"class_id\"])\n",
    "\n",
    "# Build parameters from widgets and configuration\n",
    "params = {\n",
    "    \"min_scale_cm\": object_size_slider.value[0],\n",
    "    \"max_scale_cm\": object_size_slider.value[1],\n",
    "    \"rotation_range\": tuple(rotation_slider.value),\n",
    "    \"allow_overlap\": allow_overlap.value,\n",
    "    \"max_overlap_pct\": max_overlap_pct.value,\n",
    "    \"min_object_distance_cm\": min_distance_slider.value,\n",
    "    \"edge_avoidance\": edge_margin_slider.value,\n",
    "    \"prefer_center\": center_bias_slider.value,\n",
    "    \"category_weights\": [1.0 / len(categories)] * len(categories),\n",
    "    \"object_blending_strength\": blending_slider.value,\n",
    "    \"number_of_objects_per_image\": tuple(num_objects_slider.value),\n",
    "    \"num_composite_images\": 3,\n",
    "    \"default_bg_width_cm\": default_bg_width_cm.value,\n",
    "    \"default_placement_area_pct\": (default_placement_area_width.value[0], default_placement_area_height.value[0], default_placement_area_width.value[1], default_placement_area_height.value[1]),\n",
    "    \"output_width\": width_input.value,\n",
    "    \"output_height\": height_input.value,\n",
    "    \"output_channels\": 3,\n",
    "    \"max_labels\": max_labels.value,\n",
    "    \"is_video_background\": is_video_background.value\n",
    "}\n",
    "\n",
    "# Validate parameters\n",
    "if params[\"min_scale_cm\"] >= params[\"max_scale_cm\"]:\n",
    "    print(f\"Warning: min_scale_cm ({params['min_scale_cm']}) >= max_scale_cm ({params['max_scale_cm']})\")\n",
    "    print(\"Setting max_scale_cm to min_scale_cm + 1.0\")\n",
    "    params[\"max_scale_cm\"] = params[\"min_scale_cm\"] + 1.0\n",
    "\n",
    "if params[\"number_of_objects_per_image\"][0] > params[\"number_of_objects_per_image\"][1]:\n",
    "    print(f\"Warning: Invalid object range, fixing...\")\n",
    "    params[\"number_of_objects_per_image\"] = (1, max(2, params[\"number_of_objects_per_image\"][1]))\n",
    "\n",
    "# Generate preview\n",
    "preview_dataset = create_dataset_from_generator(\n",
    "    overlay=True,\n",
    "    params=params,\n",
    "    background_images=background_images,\n",
    "    bg_widths=bg_widths,\n",
    "    bg_placement_areas=bg_placement_areas,\n",
    "    category_datasets=category_datasets,\n",
    "    category_class_ids=category_class_ids,\n",
    "    num_samples=3\n",
    ")\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 16))\n",
    "for idx, (images, labels) in enumerate(preview_dataset.take(3)):\n",
    "    axes[idx, 0].imshow(images[0].numpy())\n",
    "    axes[idx, 0].set_title(f'Background {idx+1}')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(images[1].numpy())\n",
    "    axes[idx, 1].set_title(f'With Objects {idx+1}')\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    # Draw bounding boxes (labels are now: exists, xmin, ymin, xmax, ymax, class_id in absolute pixels)\n",
    "    for label in labels:\n",
    "        exists, xmin, ymin, xmax, ymax, class_id = label.numpy()\n",
    "        if exists > 0.5:\n",
    "            # Coordinates are already in absolute pixels\n",
    "            box_w = xmax - xmin\n",
    "            box_h = ymax - ymin\n",
    "            \n",
    "            rect = plt.Rectangle((xmin, ymin), box_w, box_h,\n",
    "                                linewidth=2, edgecolor='lime', facecolor='none')\n",
    "            axes[idx, 1].add_patch(rect)\n",
    "            \n",
    "            # Class label lookup by class_id\n",
    "            cat_name = next((c['name'] for c in categories if c['class_id'] == int(class_id)), f\"Class {int(class_id)}\")\n",
    "            axes[idx, 1].text(\n",
    "                xmin, ymin - 5, cat_name,\n",
    "                color='lime', fontsize=10, weight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='black', alpha=0.5)\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d60ac1",
   "metadata": {},
   "source": [
    "## 4. Generate Full Dataset\n",
    "\n",
    "**Only run this after the preview looks good!**\n",
    "\n",
    "This will generate all images and may take a while depending on the number of images.\n",
    "\n",
    "### Output Format:\n",
    "- `image_XXXXX_temp.png`: Reference image (background only)\n",
    "- `image_XXXXX_test.png`: Test image (background + objects)\n",
    "- `image_XXXXX_test.txt`: Labels (bounding boxes)\n",
    "\n",
    "### Label Format:\n",
    "Each line in `.txt` file: `xmin ymin xmax ymax class_id`\n",
    "- Coordinates in absolute pixels\n",
    "- class_id matches your category configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update number of images\n",
    "params[\"num_composite_images\"] = num_images_input.value\n",
    "\n",
    "# Generate dataset\n",
    "print(f\"Generating {params['num_composite_images']} images...\")\n",
    "full_dataset = create_dataset_from_generator(\n",
    "    overlay=True,\n",
    "    params=params,\n",
    "    background_images=background_images,\n",
    "    bg_widths=bg_widths,\n",
    "    bg_placement_areas=bg_placement_areas,\n",
    "    category_datasets=category_datasets,\n",
    "    category_class_ids=category_class_ids,\n",
    "    num_samples=params['num_composite_images']\n",
    ")\n",
    "\n",
    "# Save to disk\n",
    "export_path = Path(output_path)\n",
    "export_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Saving to {export_path}...\")\n",
    "for idx, (images, labels) in enumerate(full_dataset):\n",
    "    # Save images\n",
    "    bg_img = (images[0].numpy() * 255).astype(np.uint8)\n",
    "    obj_img = (images[1].numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "    tf.io.write_file(str(export_path / f\"image_{idx:05d}_temp.png\"), tf.image.encode_png(bg_img))\n",
    "    tf.io.write_file(str(export_path / f\"image_{idx:05d}_test.png\"), tf.image.encode_png(obj_img))\n",
    "    \n",
    "    # Save labels in corner format: xmin ymin xmax ymax class_id (absolute pixels, 1-based)\n",
    "    with open(export_path / f\"image_{idx:05d}_test.txt\", 'w') as f:\n",
    "        for label in labels:\n",
    "            exists, xmin, ymin, xmax, ymax, class_id = label.numpy()\n",
    "            if exists > 0.5:\n",
    "                # Write in format: xmin ymin xmax ymax class_id (absolute pixel coordinates)\n",
    "                f.write(f\"{int(xmin)} {int(ymin)} {int(xmax)} {int(ymax)} {int(class_id)}\\n\")\n",
    "    \n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  {idx + 1}/{params['num_composite_images']} images saved...\")\n",
    "\n",
    "print(f\"‚úì Done! {params['num_composite_images']} images saved to {export_path}\")\n",
    "print(f\"Label format: xmin ymin xmax ymax class_id (absolute pixel coordinates, 1-based class IDs)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneai-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
